name: Deploy Real-time Data Pipeline Infrastructure

on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  GCP_SA_KEY: ${{ secrets.GCP_SA_KEY }}
  REGION: us-central1
  ENVIRONMENT: dev

jobs:
  terraform-plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.7

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ env.GCP_SA_KEY }}

    - name: Setup Google Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    - name: Terraform Init
      working-directory: ./terraform
      run: terraform init

    - name: Terraform Validate
      working-directory: ./terraform
      run: terraform validate

    - name: Terraform Plan
      working-directory: ./terraform
      run: terraform plan -out=tfplan
      env:
        TF_VAR_project_id: ${{ env.PROJECT_ID }}
        TF_VAR_environment: ${{ env.ENVIRONMENT }}

    - name: Upload Terraform Plan
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan
        path: terraform/tfplan

  terraform-apply:
    name: Terraform Apply
    runs-on: ubuntu-latest
    needs: terraform-plan
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/dev'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.7

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ env.GCP_SA_KEY }}

    - name: Setup Google Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    - name: Download Terraform Plan
      uses: actions/download-artifact@v4
      with:
        name: terraform-plan
        path: terraform/

    - name: Terraform Init
      working-directory: ./terraform
      run: terraform init

    - name: Terraform Apply
      working-directory: ./terraform
      run: terraform apply -auto-approve tfplan

    - name: Assign IAM Roles
      run: |
        echo "🔐 Assigning IAM roles to service accounts..."
        chmod +x ./scripts/assign-iam-roles.sh
        ./scripts/assign-iam-roles.sh ${{ env.PROJECT_ID }} ${{ env.ENVIRONMENT }}
        
        echo "⏳ Waiting for IAM propagation..."
        sleep 30

    - name: Handle Resource Conflicts (if needed)
      if: failure()
      working-directory: ./terraform
      run: |
        echo "🔍 Handling potential resource conflicts..."
        
        ENV="${{ env.ENVIRONMENT }}"
        PROJECT_ID="${{ env.PROJECT_ID }}"
        
        # Import existing resources to resolve conflicts
        echo "Attempting to import conflicting resources..."
        terraform import -var="project_id=$PROJECT_ID" -var="environment=$ENV" google_pubsub_topic.backend_events "projects/$PROJECT_ID/topics/$ENV-backend-events-topic" || true
        terraform import -var="project_id=$PROJECT_ID" -var="environment=$ENV" google_pubsub_topic.dead_letter "projects/$PROJECT_ID/topics/$ENV-backend-events-dead-letter" || true
        terraform import -var="project_id=$PROJECT_ID" -var="environment=$ENV" google_bigquery_dataset.events_dataset "projects/$PROJECT_ID/datasets/${ENV}_events_dataset" || true
        
        # Try applying again
        echo "Retrying terraform apply after imports..."
        terraform apply -auto-approve || {
          echo "❌ Terraform apply failed again. Triggering cleanup..."
          exit 1
        }
        
        # If successful, assign IAM roles
        echo "🔐 Assigning IAM roles after successful terraform retry..."
        chmod +x ../scripts/assign-iam-roles.sh
        ../scripts/assign-iam-roles.sh "$PROJECT_ID" "$ENV"
        sleep 30
      continue-on-error: false
      env:
        TF_VAR_project_id: ${{ env.PROJECT_ID }}
        TF_VAR_environment: ${{ env.ENVIRONMENT }}

  deploy-cloud-function:
    name: Deploy Cloud Function
    runs-on: ubuntu-latest
    needs: terraform-apply
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/dev'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ env.GCP_SA_KEY }}

    - name: Setup Google Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.7

    - name: Deploy Cloud Function
      run: |
        chmod +x ./scripts/deploy-cloud-function.sh
        ./scripts/deploy-cloud-function.sh ${{ env.PROJECT_ID }} ${{ env.ENVIRONMENT }}

    - name: Update Cloud Function via Terraform
      working-directory: ./terraform
      run: |
        terraform init
        terraform apply -auto-approve
      env:
        TF_VAR_project_id: ${{ env.PROJECT_ID }}
        TF_VAR_environment: ${{ env.ENVIRONMENT }}

  deploy-event-generator:
    name: Deploy Event Generator Service
    runs-on: ubuntu-latest
    needs: terraform-apply
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/dev'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ env.GCP_SA_KEY }}

    - name: Setup Google Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    - name: Deploy Event Generator to Cloud Run
      run: |
        chmod +x ./scripts/deploy-event-generator.sh
        ./scripts/deploy-event-generator.sh ${{ env.PROJECT_ID }} ${{ env.ENVIRONMENT }} ${{ env.REGION }}

    - name: Test Event Generator Service
      run: |
        # Get service URL from terraform output or gcloud
        SERVICE_NAME="${{ env.ENVIRONMENT }}-event-generator"
        SERVICE_URL=$(gcloud run services describe $SERVICE_NAME --region=${{ env.REGION }} --format="value(status.url)")
        
        echo "Testing Event Generator service at: $SERVICE_URL"
        
        # Test health endpoint
        curl -f "$SERVICE_URL/health" || exit 1
        
        # Test sample event generation
        curl -f "$SERVICE_URL/sample/order" || exit 1
        
        # Test scenarios endpoint
        curl -f "$SERVICE_URL/scenarios" || exit 1
        
        echo "✅ Event Generator service is healthy and responding"

  build-dataflow-template:
    name: Build and Deploy Dataflow Template
    runs-on: ubuntu-latest
    needs: [terraform-apply, deploy-event-generator]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/dev'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ env.GCP_SA_KEY }}

    - name: Setup Google Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.7

    - name: Configure Docker for GCR
      run: gcloud auth configure-docker

    - name: Build and Deploy Dataflow Template
      run: |
        chmod +x ./scripts/deploy-dataflow-template.sh
        ./scripts/deploy-dataflow-template.sh ${{ env.PROJECT_ID }} ${{ env.ENVIRONMENT }} ${{ env.REGION }}

    - name: Deploy Dataflow Job via Terraform
      working-directory: ./terraform
      run: |
        terraform init
        terraform apply -auto-approve
      env:
        TF_VAR_project_id: ${{ env.PROJECT_ID }}
        TF_VAR_environment: ${{ env.ENVIRONMENT }}

  test-pipeline:
    name: Test Data Pipeline
    runs-on: ubuntu-latest
    needs: [deploy-cloud-function, deploy-event-generator, build-dataflow-template]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/dev'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ env.GCP_SA_KEY }}

    - name: Setup Google Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    - name: Wait for Infrastructure
      run: sleep 60  # Wait for services to be fully ready

    - name: Run Integration Tests
      run: |
        chmod +x ./scripts/test-table-creation.sh
        ./scripts/test-table-creation.sh ${{ env.PROJECT_ID }} ${{ env.ENVIRONMENT }}

    - name: Verify Dataflow Job
      run: |
        JOB_NAME="${{ env.ENVIRONMENT }}-realtime-data-pipeline"
        gcloud dataflow jobs list --region=${{ env.REGION }} --filter="name:${JOB_NAME}" --format="value(id)" | head -1

    - name: Check BigQuery Tables
      run: |
        DATASET="${{ env.ENVIRONMENT }}_events_dataset"
        bq ls --project_id=${{ env.PROJECT_ID }} $DATASET

  cleanup-on-failure:
    name: Cleanup on Failure
    runs-on: ubuntu-latest
    needs: [terraform-apply, deploy-cloud-function, deploy-event-generator, build-dataflow-template, test-pipeline]
    if: failure()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.7

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ env.GCP_SA_KEY }}

    - name: Setup Google Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    - name: Get Environment
      id: env
      run: |
        ENV="${{ env.ENVIRONMENT }}"
        echo "environment=$ENV" >> $GITHUB_OUTPUT
        echo "Detected environment: $ENV"

    - name: Initialize Terraform for Cleanup
      working-directory: ./terraform
      run: terraform init
      continue-on-error: true

    - name: Import Existing Resources (Handle Conflicts)
      working-directory: ./terraform
      run: |
        ENV="${{ steps.env.outputs.environment }}"
        PROJECT_ID="${{ env.PROJECT_ID }}"
        
        echo "Attempting to import existing resources to handle conflicts..."
        
        # Import Pub/Sub topics if they exist
        terraform import -var="project_id=$PROJECT_ID" -var="environment=$ENV" \
          google_pubsub_topic.backend_events \
          "projects/$PROJECT_ID/topics/$ENV-backend-events-topic" || true
          
        terraform import -var="project_id=$PROJECT_ID" -var="environment=$ENV" \
          google_pubsub_topic.dead_letter \
          "projects/$PROJECT_ID/topics/$ENV-backend-events-dead-letter" || true
          
        # Import BigQuery dataset if it exists
        terraform import -var="project_id=$PROJECT_ID" -var="environment=$ENV" \
          google_bigquery_dataset.events_dataset \
          "projects/$PROJECT_ID/datasets/${ENV}_events_dataset" || true
          
        echo "Import completed (errors expected for non-existing resources)"
      continue-on-error: true

    - name: Run Comprehensive Cleanup
      run: |
        chmod +x ./scripts/cleanup-all-resources.sh
        
        ENV="${{ steps.env.outputs.environment }}"
        PROJECT_ID="${{ env.PROJECT_ID }}"
        
        echo "🧹 Starting comprehensive cleanup for environment: $ENV"
        echo "Project ID: $PROJECT_ID"
        
        # Run our comprehensive cleanup script
        ./scripts/cleanup-all-resources.sh --auto-approve --project-id="$PROJECT_ID" --environment="$ENV"
      continue-on-error: true

    - name: Manual Resource Cleanup (Fallback)
      if: always()
      run: |
        ENV="${{ steps.env.outputs.environment }}"
        PROJECT_ID="${{ env.PROJECT_ID }}"
        REGION="${{ env.REGION }}"
        
        echo "🔄 Running manual cleanup as fallback for demo environment..."
        
        # Stop and delete Dataflow jobs
        echo "Cleaning up Dataflow jobs..."
        gcloud dataflow jobs list --region=$REGION --filter="name:$ENV-realtime-data-pipeline" --format="value(id)" | while read job_id; do
          if [ ! -z "$job_id" ]; then
            echo "Stopping Dataflow job: $job_id"
            gcloud dataflow jobs cancel $job_id --region=$REGION || true
          fi
        done
        
        # Delete Cloud Run services
        echo "Cleaning up Cloud Run services..."
        gcloud run services delete "$ENV-event-generator" --region=$REGION --quiet || true
        
        # Delete Cloud Functions
        echo "Cleaning up Cloud Functions..."
        gcloud functions delete "$ENV-table-manager" --region=$REGION --quiet || true
        
        # Delete Pub/Sub topics and subscriptions
        echo "Cleaning up Pub/Sub resources..."
        gcloud pubsub subscriptions delete "$ENV-backend-events-subscription" || true
        gcloud pubsub topics delete "$ENV-backend-events-topic" || true
        gcloud pubsub topics delete "$ENV-backend-events-dead-letter" || true
        
        # Delete BigQuery dataset (demo environment)
        echo "Cleaning up BigQuery dataset..."
        bq rm -r -f -d "$PROJECT_ID:${ENV}_events_dataset" || true
        
        # Delete Cloud Storage buckets (demo environment)
        echo "Cleaning up Cloud Storage buckets..."
        gsutil -m rm -r "gs://$PROJECT_ID-$ENV-raw-events" || true
        gsutil -m rm -r "gs://$PROJECT_ID-$ENV-dataflow-temp" || true
        gsutil -m rm -r "gs://$PROJECT_ID-$ENV-dataflow-templates" || true
        gsutil -m rm -r "gs://$PROJECT_ID-$ENV-function-source" || true
        
        # Delete Container Registry images
        echo "Cleaning up Container Registry images..."
        gcloud container images list --repository=gcr.io/$PROJECT_ID --format="value(name)" | grep -E "(event-generator|table-manager)" | while read image; do
          gcloud container images delete $image --force-delete-tags --quiet || true
        done
        
        # Delete service accounts (demo environment)
        echo "Cleaning up service accounts..."
        gcloud iam service-accounts delete "$ENV-dataflow-pipeline-sa@$PROJECT_ID.iam.gserviceaccount.com" --quiet || true
        gcloud iam service-accounts delete "$ENV-table-manager-sa@$PROJECT_ID.iam.gserviceaccount.com" --quiet || true
        gcloud iam service-accounts delete "$ENV-event-generator-sa@$PROJECT_ID.iam.gserviceaccount.com" --quiet || true
        
        echo "🏁 Manual cleanup completed for demo environment"
      continue-on-error: true

    - name: Cleanup Summary
      if: always()
      run: |
        ENV="${{ steps.env.outputs.environment }}"
        echo "🔍 Demo Project Cleanup Summary"
        echo "============================================="
        echo "Environment: $ENV (demo only)"
        echo "✅ Comprehensive cleanup script executed"
        echo "✅ Manual fallback cleanup executed"
        echo "⚠️  Some resources may require manual intervention"
        echo ""
        echo "To verify cleanup completion, run:"
        echo "  gcloud dataflow jobs list --region=${{ env.REGION }}"
        echo "  gcloud run services list --region=${{ env.REGION }}"
        echo "  gcloud functions list --region=${{ env.REGION }}"
        echo "  gcloud pubsub topics list"
        echo "  gcloud iam service-accounts list"
        echo ""
        echo "📧 Please review your GCP console and billing to ensure all demo resources are cleaned up" 